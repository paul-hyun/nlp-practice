{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e1b6bc1-9d0b-4840-b82d-788da26fb467",
   "metadata": {
    "id": "8e1b6bc1-9d0b-4840-b82d-788da26fb467",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a654fc9-033f-4adf-ba2d-2936ad6603d8",
   "metadata": {
    "id": "6a654fc9-033f-4adf-ba2d-2936ad6603d8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import collections\n",
    "from datetime import datetime\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import (\n",
    "    T5TokenizerFast,\n",
    "    AutoTokenizer\n",
    ")\n",
    "from tokenizers import ByteLevelBPETokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6489a088-eaec-4250-98a0-2b0d25dd59e8",
   "metadata": {
    "id": "6489a088-eaec-4250-98a0-2b0d25dd59e8"
   },
   "outputs": [],
   "source": [
    "# Gradient False\n",
    "torch.set_grad_enabled(True)\n",
    "# work dir\n",
    "work_dir = '/home/ubuntu/nlp-practice'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31MiVvMwQs5F",
   "metadata": {
    "id": "31MiVvMwQs5F"
   },
   "outputs": [],
   "source": [
    "%cd {work_dir}\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60aa673d",
   "metadata": {
    "id": "60aa673d",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 3.0 NMT Preprocessing & Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e98a21",
   "metadata": {
    "id": "24e98a21"
   },
   "outputs": [],
   "source": [
    "%cd {work_dir}/src/nmt\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1719c9a8",
   "metadata": {
    "id": "1719c9a8"
   },
   "outputs": [],
   "source": [
    "fn_list = []\n",
    "for fn in os.listdir('../../data/aihub_koen'):\n",
    "    if fn.endswith('.xlsx'):\n",
    "        fn_list.append(f'../../data/aihub_koen/{fn}')\n",
    "fn_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8443decf",
   "metadata": {
    "id": "8443decf"
   },
   "outputs": [],
   "source": [
    "pd.read_excel(fn_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2802aa",
   "metadata": {
    "id": "5d2802aa"
   },
   "outputs": [],
   "source": [
    "!sh ./preprocess.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124ad589",
   "metadata": {
    "id": "124ad589"
   },
   "outputs": [],
   "source": [
    "!sh ./tokenizer_train.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f7c766-5bf7-444c-b0e1-b1e1e0ac7445",
   "metadata": {
    "id": "b2f7c766-5bf7-444c-b0e1-b1e1e0ac7445",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 3.1 Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liXnk7A2cG2K",
   "metadata": {
    "id": "liXnk7A2cG2K"
   },
   "outputs": [],
   "source": [
    "%cd {work_dir}/src/lm\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ec88b8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## tutorial language model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c544d18",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### input & embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315f5d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = [\n",
    "    \"<s>나는 학생입니다.\",\n",
    "    \"<s>나는 학교에 가는 것을 좋아합니다.\"\n",
    "]\n",
    "label_text = [\n",
    "    \"나는 학생입니다.</s>\",\n",
    "    \"나는 학교에 가는 것을 좋아합니다.</s>\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72469cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5TokenizerFast.from_pretrained('../../data/aihub_koen_32k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db72e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(input_text,\n",
    "                    padding=True,\n",
    "                    truncation=True,\n",
    "                    max_length=128,\n",
    "                    return_tensors=\"pt\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3dc2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tokenizer(label_text,\n",
    "                    padding=True,\n",
    "                    truncation=True,\n",
    "                    max_length=128,\n",
    "                    return_tensors=\"pt\")\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40000f8d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52adeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = 2\n",
    "embedding_dim = 3\n",
    "hidden_dim = 4\n",
    "vocab_size = tokenizer.vocab_size\n",
    "pad_idx = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb6bac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "lstm = nn.LSTM(\n",
    "    embedding_dim,\n",
    "    hidden_dim,\n",
    "    num_layers=n_layers,\n",
    "    bidirectional=False,  # bidirectional=False for Lanugage Model\n",
    "    batch_first=True,  # If False, input shape is (seq_len, batch_size, input_size).\n",
    ")\n",
    "\n",
    "# Note that we use \"vocab_size\" sence we are prediting vocab.\n",
    "fc = nn.Linear(hidden_dim, vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101d9a36",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cae24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = embedding(inputs['input_ids'])\n",
    " # |embed| = (batch_size, seq_len_enc, embedding_dim)\n",
    "embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578b3414",
   "metadata": {},
   "outputs": [],
   "source": [
    "output, (hidden_l, cell_l) = lstm(embed)\n",
    "# |output| = (batch_size, seq_len, hidden_dim)\n",
    "# |hidden_l| = (n_layers, batch_size, hidden_dim)\n",
    "# |cell_l| = (n_layers, batch_size, hidden_dim)\n",
    "output, hidden_l, cell_l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c21de1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### linear & softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d17eebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848bf614",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = fc(hidden)\n",
    "# |logits| = (batch_size, seq_len_dec, vocab_size)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a207b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = F.softmax(logits, dim=-1)\n",
    "prob.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7286bf23",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6c4d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b56b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_id = labels['input_ids']\n",
    "labels_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aaa5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(logits.view(-1, logits.size(-1)), labels_id.view(-1,))\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474a87eb-df2f-43d5-b3a3-b1c0076ca7d9",
   "metadata": {
    "id": "474a87eb-df2f-43d5-b3a3-b1c0076ca7d9",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## train rnn lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_05P1LxOmJCe",
   "metadata": {
    "id": "_05P1LxOmJCe"
   },
   "outputs": [],
   "source": [
    "# run src/lm/train_rnn.sh\n",
    "!sh train_rnn.sh \"cchyun-rnn-lm\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tMB_z6saWoz2",
   "metadata": {
    "id": "tMB_z6saWoz2",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## generate rnn lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rGaBz4EdWoz3",
   "metadata": {
    "id": "rGaBz4EdWoz3"
   },
   "outputs": [],
   "source": [
    "# run src/lm/generate_rnn.sh\n",
    "!sh generate_rnn.sh \"../../checkpoints/cchyun-rnn-lm-20240416-072303.pt\" \"지미카터\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2PUCDkJ4b9ys",
   "metadata": {
    "id": "2PUCDkJ4b9ys",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 3.2 Seq to Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KLssMTaJT4Xg",
   "metadata": {
    "id": "KLssMTaJT4Xg"
   },
   "outputs": [],
   "source": [
    "%cd {work_dir}/src/nmt\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70272216",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## tutorial seq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf66c3a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### input & embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b706843",
   "metadata": {},
   "outputs": [],
   "source": [
    "ko = [\n",
    "    \"나는 학생입니다.\",\n",
    "    \"나는 학교에 가는 것을 좋아합니다.\"\n",
    "]\n",
    "en = [\n",
    "    \"<s>I am a student.\",\n",
    "    \"<s>I love to go to school.\"\n",
    "]\n",
    "label_text = [\n",
    "    \"I am a student.</s>\",\n",
    "    \"I love to go to school.</s>\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18beca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5TokenizerFast.from_pretrained('../../data/aihub_koen_32k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f31e710",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_inputs = tokenizer(ko,\n",
    "                       padding=True,\n",
    "                       truncation=True,\n",
    "                       max_length=128,\n",
    "                       return_tensors=\"pt\")\n",
    "enc_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88dfba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_inputs = tokenizer(en,\n",
    "                       padding=True,\n",
    "                       truncation=True,\n",
    "                       max_length=128,\n",
    "                       return_tensors=\"pt\")\n",
    "dec_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdc2564",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tokenizer(label_text,\n",
    "                    padding=True,\n",
    "                    truncation=True,\n",
    "                    max_length=128,\n",
    "                    return_tensors=\"pt\")\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a306d452",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45523d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = 2\n",
    "hidden_dim = 4\n",
    "vocab_size = tokenizer.vocab_size\n",
    "pad_idx = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe01186a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(vocab_size, hidden_dim, padding_idx=pad_idx)\n",
    "\n",
    "encoder = nn.LSTM(\n",
    "    hidden_dim,\n",
    "    hidden_dim // 2,\n",
    "    num_layers=n_layers,\n",
    "    bidirectional=True,  # bidirectional=True for Encoder\n",
    "    dropout=0.1,\n",
    "    batch_first=True,  # If False, input shape is (seq_len, batch_size, input_size).\n",
    ")\n",
    "\n",
    "decoder = nn.LSTM(\n",
    "    hidden_dim,\n",
    "    hidden_dim,  # encoder bidirectional=True, decode bidirectional=False\n",
    "    num_layers=n_layers,\n",
    "    bidirectional=False,  # bidirectional=False for Decoder (LM)\n",
    "    dropout=0.1,\n",
    "    batch_first=True,  # If False, input shape is (seq_len, batch_size, input_size).\n",
    ")\n",
    "\n",
    "# Note that we use \"vocab_size\" sence we are prediting vocab.\n",
    "fc = nn.Linear(hidden_dim, vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9067c5e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab7b19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_embed = embedding(enc_inputs['input_ids'])\n",
    " # |enc_embed| = (batch_size, seq_len_enc, embedding_dim)\n",
    "enc_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65201b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_out, (hidden_e, cell_e) = encoder(enc_embed)\n",
    "# |enc_out| = (batch_size, seq_len_enc, hidden_dim)\n",
    "# |hidden| = (n_layers * 2, batch_size, hidden_dim // 2)\n",
    "# |cell| = (n_layers * 2, batch_size, hidden_dim // 2)\n",
    "enc_out, hidden_e, cell_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fecc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = torch.cat((hidden_e[0::2], hidden_e[1::2]), dim=-1)\n",
    "# |hidden| = (n_layers, batch_size, hidden_dim)\n",
    "cell = torch.cat((cell_e[0::2], cell_e[1::2]), dim=-1)\n",
    "# |hidden| = (n_layers, batch_size, hidden_dim)\n",
    "hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce0537d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d220d084",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_embed = embedding(dec_inputs['input_ids'])\n",
    "dec_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2ddade",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_out, (hidden, cell) = decoder(dec_embed, (hidden, cell))\n",
    "# |dec_out| = (batch_size, seq_len_dec, hidden_dim)\n",
    "# |hidden| = (n_layers, batch_size, hidden_dim)\n",
    "# |cell| = (n_layers, batch_size, hidden_dim)\n",
    "dec_out, hidden_e, cell_e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39813de3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### linear & softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40226479",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = dec_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c819d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = fc(hidden)\n",
    "# |logits| = (batch_size, seq_len_dec, vocab_size)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4031d9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = F.softmax(logits, dim=-1)\n",
    "prob.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc160fd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f457a79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f99ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_id = labels['input_ids']\n",
    "labels_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290bf10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(logits.view(-1, logits.size(-1)), labels_id.view(-1,))\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "H2McBvS_X1TE",
   "metadata": {
    "id": "H2McBvS_X1TE",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## train seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3M_pvVI-X1TE",
   "metadata": {
    "id": "3M_pvVI-X1TE"
   },
   "outputs": [],
   "source": [
    "# run src/nmt/train_seq2seq.sh\n",
    "!sh ./train_seq2seq.sh \"cchyun-rnn-nmt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ExuAioNUYIx9",
   "metadata": {
    "id": "ExuAioNUYIx9",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## translate seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kX5KKZlwYIx-",
   "metadata": {
    "id": "kX5KKZlwYIx-"
   },
   "outputs": [],
   "source": [
    "# run src/nmt/translate_seq2seq.sh\n",
    "!sh ./translate_seq2seq.sh \"../../checkpoints/cchyun-rnn-nmt-20240322-022551.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc718c77",
   "metadata": {
    "id": "fc718c77",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## infer seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96f330f",
   "metadata": {
    "id": "d96f330f"
   },
   "outputs": [],
   "source": [
    "from seq2seq import Seq2SeqTranslator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c807cc11",
   "metadata": {
    "id": "c807cc11"
   },
   "outputs": [],
   "source": [
    "device = (\n",
    "    torch.device(\"cpu\")\n",
    ")\n",
    "\n",
    "model_fn = \"../../checkpoints/cchyun-rnn-nmt-20240322-022551.pt\"\n",
    "\n",
    "data = torch.load(model_fn, map_location=device)\n",
    "train_config = data[\"config\"]\n",
    "label2idx = data[\"label2idx\"]\n",
    "idx2label = data[\"idx2label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148f6a88",
   "metadata": {
    "id": "148f6a88"
   },
   "outputs": [],
   "source": [
    "tokenizer = T5TokenizerFast.from_pretrained(train_config.tokenizer)\n",
    "tokenizer.bos_token = \"<s>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650cd805",
   "metadata": {
    "id": "650cd805"
   },
   "outputs": [],
   "source": [
    "model = Seq2SeqTranslator(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    hidden_dim=train_config.hidden_dim,\n",
    "    n_layers=train_config.n_layers,\n",
    "    dropout=train_config.dropout,\n",
    "    pad_idx=tokenizer.pad_token_id,\n",
    ")\n",
    "model.load_state_dict(data[\"model\"])\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acbb7bb",
   "metadata": {
    "id": "7acbb7bb"
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    print(\"input> \", end=\"\")\n",
    "    line = str(input())\n",
    "    if len(line) == 0:\n",
    "        break\n",
    "\n",
    "    x = tokenizer(\n",
    "        line,\n",
    "        truncation=True,\n",
    "        max_length=train_config.max_length,\n",
    "        return_tensors=\"np\",\n",
    "    )[\"input_ids\"]\n",
    "\n",
    "    output_ids = model.generate(\n",
    "        list(x[0]), 50, tokenizer.bos_token_id, tokenizer.eos_token_id\n",
    "    )\n",
    "    result = tokenizer.decode(output_ids)\n",
    "\n",
    "    print(f\"- ko: {line}\\n- en: {result}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7932cc2-1bf8-4cb3-b83f-a8335804adcc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 3.3. Seq2Seq + Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ca3b37-2744-4a67-ba09-6ffe31d13295",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd {work_dir}/src/nmt\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459eda04",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## tutorial attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e623bd0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### input & labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d27213",
   "metadata": {},
   "outputs": [],
   "source": [
    "ko = [\n",
    "    \"나는 학생입니다.\",\n",
    "    \"나는 학교에 가는 것을 좋아합니다.\"\n",
    "]\n",
    "en = [\n",
    "    \"<s>I am a student.\",\n",
    "    \"<s>I love to go to school.\"\n",
    "]\n",
    "label_text = [\n",
    "    \"I am a student.</s>\",\n",
    "    \"I love to go to school.</s>\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ddb5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5TokenizerFast.from_pretrained('../../data/aihub_koen_32k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c908821",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_inputs = tokenizer(ko,\n",
    "                       padding=True,\n",
    "                       truncation=True,\n",
    "                       max_length=128,\n",
    "                       return_tensors=\"pt\")\n",
    "enc_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072a9c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_inputs = tokenizer(en,\n",
    "                       padding=True,\n",
    "                       truncation=True,\n",
    "                       max_length=128,\n",
    "                       return_tensors=\"pt\")\n",
    "dec_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53893c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tokenizer(label_text,\n",
    "                    padding=True,\n",
    "                    truncation=True,\n",
    "                    max_length=128,\n",
    "                    return_tensors=\"pt\")\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff93595",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4b46f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = 2\n",
    "hidden_dim = 4\n",
    "vocab_size = tokenizer.vocab_size\n",
    "pad_idx = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7088de7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(vocab_size, hidden_dim, padding_idx=pad_idx)\n",
    "\n",
    "encoder = nn.LSTM(\n",
    "    hidden_dim,\n",
    "    hidden_dim // 2,\n",
    "    num_layers=n_layers,\n",
    "    bidirectional=True,  # bidirectional=True for Encoder\n",
    "    dropout=0.1,\n",
    "    batch_first=True,  # If False, input shape is (seq_len, batch_size, input_size).\n",
    ")\n",
    "\n",
    "decoder = nn.LSTM(\n",
    "    hidden_dim,\n",
    "    hidden_dim,  # encoder bidirectional=True, decode bidirectional=False\n",
    "    num_layers=n_layers,\n",
    "    bidirectional=False,  # bidirectional=False for Decoder (LM)\n",
    "    dropout=0.1,\n",
    "    batch_first=True,  # If False, input shape is (seq_len, batch_size, input_size).\n",
    ")\n",
    "\n",
    "attn_w = nn.Linear(hidden_dim, hidden_dim)\n",
    "concat_w = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "\n",
    "# Note that we use \"vocab_size\" sence we are prediting vocab.\n",
    "fc = nn.Linear(hidden_dim, vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090fd745",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c5209e",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_embed = embedding(enc_inputs['input_ids'])\n",
    " # |enc_embed| = (batch_size, seq_len_enc, embedding_dim)\n",
    "enc_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f5b49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_out, (hidden_e, cell_e) = encoder(enc_embed)\n",
    "# |enc_out| = (batch_size, seq_len_enc, hidden_dim)\n",
    "# |hidden| = (n_layers * 2, batch_size, hidden_dim // 2)\n",
    "# |cell| = (n_layers * 2, batch_size, hidden_dim // 2)\n",
    "enc_out, hidden_e, cell_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38acc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = torch.cat((hidden_e[0::2], hidden_e[1::2]), dim=-1)\n",
    "# |hidden| = (n_layers, batch_size, hidden_dim)\n",
    "cell = torch.cat((cell_e[0::2], cell_e[1::2]), dim=-1)\n",
    "# |hidden| = (n_layers, batch_size, hidden_dim)\n",
    "hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53492103",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7c47ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_embed = embedding(dec_inputs['input_ids'])\n",
    "dec_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834950eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_out, (hidden, cell) = decoder(dec_embed, (hidden, cell))\n",
    "# |dec_out| = (batch_size, seq_len_dec, hidden_dim)\n",
    "# |hidden| = (n_layers, batch_size, hidden_dim)\n",
    "# |cell| = (n_layers, batch_size, hidden_dim)\n",
    "dec_out, hidden_e, cell_e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7457dc82",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd9d4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = dec_out\n",
    "K = enc_out\n",
    "V = enc_out\n",
    "attention_mask = enc_inputs['attention_mask']\n",
    "# |Q| = (batch_size, Q_len, hidden_dim)\n",
    "# |K| = (batch_size, K_len, hidden_dim)\n",
    "# |V| = (batch_size, K_len, hidden_dim)\n",
    "# |attention_mask| = (batch_size, K_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec60f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = attn_w(Q)\n",
    "# |Q| = (batch_size, Q_len, hidden_dim)\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b325005",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_score = torch.matmul(Q, K.transpose(-2, -1).contiguous())\n",
    "# |attn_score| = (batch_size, Q_len, K_len)\n",
    "attn_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490ac721",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = attention_mask.unsqueeze(1)\n",
    "# |attention_mask| = (batch_size, 1, K_len)\n",
    "attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c89879",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_score -= (1 - attention_mask) * 1e9\n",
    "# |attn_score| = (batch_size, Q_len, K_len)\n",
    "attn_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50baab64",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_prob = F.softmax(attn_score, dim=-1)\n",
    "# |attn_prob| = (batch_size, Q_len, K_len)\n",
    "attn_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cc60f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_out = torch.matmul(attn_prob, V)\n",
    "# |attn_out| = (batch_size, Q_len, hidden_dim)\n",
    "attn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fd312f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = torch.cat([Q, attn_out], dim=-1)\n",
    "# |hidden| = (batch_size, Q_len, hidden_dim * 2)\n",
    "hidden = concat_w(hidden)\n",
    "hidden = F.tanh(hidden)\n",
    "# |hidden| = (batch_size, Q_len, hidden_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3effe2ba",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### linear & softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeac07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = fc(hidden)\n",
    "# |logits| = (batch_size, seq_len_dec, vocab_size)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c84f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = F.softmax(logits, dim=-1)\n",
    "prob.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c13746",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94da2499",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e063eda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_id = labels['input_ids']\n",
    "labels_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b9d542",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(logits.view(-1, logits.size(-1)), labels_id.view(-1,))\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09356afd",
   "metadata": {
    "id": "09356afd",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## train seq2seq attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc4fc4c",
   "metadata": {
    "id": "fdc4fc4c"
   },
   "outputs": [],
   "source": [
    "# run src/nmt/train_seq2seq_attention.sh\n",
    "!sh train_seq2seq_attention.sh \"cchyun-attn-nmt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67047962",
   "metadata": {
    "id": "67047962",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## translate seq2seq attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52aab21",
   "metadata": {
    "id": "c52aab21"
   },
   "outputs": [],
   "source": [
    "# run src/nmt/translate_seq2seq_attention.sh\n",
    "!sh translate_seq2seq_attention.sh \"../../checkpoints/cchyun-attn-nmt-20240328-050402.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65441a4e",
   "metadata": {
    "id": "65441a4e",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## infer seq2seq attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b582ce6",
   "metadata": {
    "id": "7b582ce6"
   },
   "outputs": [],
   "source": [
    "from seq2seq_attn import Seq2SeqAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5266194",
   "metadata": {
    "id": "b5266194"
   },
   "outputs": [],
   "source": [
    "device = (\n",
    "    torch.device(\"cpu\")\n",
    ")\n",
    "\n",
    "model_fn = \"../../checkpoints/cchyun-attn-nmt-20240328-050402.pt\"\n",
    "\n",
    "data = torch.load(model_fn, map_location=device)\n",
    "train_config = data[\"config\"]\n",
    "label2idx = data[\"label2idx\"]\n",
    "idx2label = data[\"idx2label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a98c80",
   "metadata": {
    "id": "c4a98c80"
   },
   "outputs": [],
   "source": [
    "tokenizer = T5TokenizerFast.from_pretrained(train_config.tokenizer)\n",
    "tokenizer.bos_token = \"<s>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606abbfc",
   "metadata": {
    "id": "606abbfc"
   },
   "outputs": [],
   "source": [
    "model = Seq2SeqAttention(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    hidden_dim=train_config.hidden_dim,\n",
    "    n_layers=train_config.n_layers,\n",
    "    dropout=train_config.dropout,\n",
    "    pad_idx=tokenizer.pad_token_id,\n",
    ")\n",
    "model.load_state_dict(data[\"model\"])\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72f5cc0",
   "metadata": {
    "id": "d72f5cc0"
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    print(\"input> \", end=\"\")\n",
    "    line = str(input())\n",
    "    if len(line) == 0:\n",
    "        break\n",
    "\n",
    "    x = tokenizer(\n",
    "        line,\n",
    "        truncation=True,\n",
    "        max_length=train_config.max_length,\n",
    "        return_tensors=\"np\",\n",
    "    )[\"input_ids\"]\n",
    "\n",
    "    output_ids = model.generate(\n",
    "        list(x[0]), 50, tokenizer.bos_token_id, tokenizer.eos_token_id\n",
    "    )\n",
    "    result = tokenizer.decode(output_ids)\n",
    "\n",
    "    print(f\"- ko: {line}\\n- en: {result}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd8fac1",
   "metadata": {
    "id": "ccd8fac1",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 3.4. Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15ffc4d",
   "metadata": {
    "id": "e15ffc4d"
   },
   "outputs": [],
   "source": [
    "%cd {work_dir}/src/transformer\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761b04dd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## tutorial trnasformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64d4217",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### input & embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a379938",
   "metadata": {},
   "outputs": [],
   "source": [
    "ko = [\n",
    "    \"나는 학생입니다.\",\n",
    "    \"나는 학교에 가는 것을 좋아합니다.\"\n",
    "]\n",
    "en = [\n",
    "    \"<s>I am a student.\",\n",
    "    \"<s>I love to go to school.\"\n",
    "]\n",
    "label = [\n",
    "    \"I am a student.<s/>\",\n",
    "    \"I love to go to school.<s/>\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a214ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5TokenizerFast.from_pretrained('../../data/aihub_koen_32k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e437573",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_inputs = tokenizer(ko,\n",
    "                       padding=True,\n",
    "                       truncation=True,\n",
    "                       max_length=128,\n",
    "                       return_tensors=\"pt\")\n",
    "enc_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3be40dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_inputs = tokenizer(en,\n",
    "                       padding=True,\n",
    "                       truncation=True,\n",
    "                       max_length=128,\n",
    "                       return_tensors=\"pt\")\n",
    "dec_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11619149",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_mask = enc_inputs['attention_mask'].unsqueeze(1)\n",
    "enc_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3f210f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_len = dec_inputs['input_ids'].shape[1]\n",
    "dec_mask = torch.ones(dec_len, dec_len)\n",
    "dec_mask = 1 - dec_mask.triu(diagonal=1)\n",
    "dec_mask = dec_mask.unsqueeze(0)\n",
    "dec_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdeac50",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 4\n",
    "vocab_size = tokenizer.vocab_size\n",
    "pad_idx = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74f9ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(vocab_size, hidden_dim, padding_idx=pad_idx)\n",
    "enc_hidden = embedding(enc_inputs['input_ids'])\n",
    "dec_hidden = embedding(dec_inputs['input_ids'])\n",
    "enc_hidden, dec_hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cc7d57",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### scale-dot product attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e10dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_dot_product_attention(Q, K, V, attention_mask):\n",
    "    # |Q| = (batch_size, n_head, Q_len, hidden_dim)\n",
    "    # |K| = (batch_size, n_head, K_len, hidden_dim)\n",
    "    # |V| = (batch_size, n_head, K_len, hidden_dim)\n",
    "    # |attention_mask| = (batch_size, 1, 1 or K_len, K_len)\n",
    "\n",
    "    # d_k\n",
    "    d_k = torch.tensor(K.shape[-1], dtype=K.dtype, device=K.device)\n",
    "    scale = torch.sqrt(d_k) # scalar\n",
    "    # |Q| = (batch_size, n_head, Q_len, hidden_dim)\n",
    "    attn_score = torch.matmul(Q, K.transpose(-2, -1).contiguous())\n",
    "    attn_score = attn_score.div(scale)\n",
    "    attn_score -= (1 - attention_mask) * 1e9\n",
    "    # |attn_score| = (batch_size, n_head, Q_len, K_len)\n",
    "    attn_prob = F.softmax(attn_score, dim=-1)\n",
    "    print(attn_prob)\n",
    "    # |attn_prob| = (batch_size, n_head, Q_len, K_len)\n",
    "    attn_out = torch.matmul(attn_prob, V)\n",
    "    # |attn_out| = (batch_size, n_head, Q_len, hidden_dim)\n",
    "    return attn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef599c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder self attention\n",
    "Q = enc_hidden\n",
    "K = enc_hidden\n",
    "V = enc_hidden\n",
    "attention_mask = enc_mask\n",
    "\n",
    "scale_dot_product_attention(Q, K, V, attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5f1fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder self attention\n",
    "Q = dec_hidden\n",
    "K = dec_hidden\n",
    "V = dec_hidden\n",
    "attention_mask = dec_mask\n",
    "\n",
    "scale_dot_product_attention(Q, K, V, attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ee8820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross attention\n",
    "Q = dec_hidden\n",
    "K = enc_hidden\n",
    "V = enc_hidden\n",
    "attention_mask = enc_mask\n",
    "\n",
    "scale_dot_product_attention(Q, K, V, attention_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438061c0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### multi head attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1435825",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_head = 2\n",
    "d_head = hidden_dim // n_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1319a77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_Q = torch.nn.Linear(hidden_dim, n_head * d_head)\n",
    "W_K = torch.nn.Linear(hidden_dim, n_head * d_head)\n",
    "W_V = torch.nn.Linear(hidden_dim, n_head * d_head)\n",
    "W_O = torch.nn.Linear(n_head * d_head, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6911b0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_head_product_attention(Q, K, V, attention_mask):\n",
    "    # |Q| = (batch_size, Q_len, hidden_dim)\n",
    "    # |K| = (batch_size, K_len, hidden_dim)\n",
    "    # |V| = (batch_size, K_len, hidden_dim)\n",
    "    # |attention_mask| = (batch_size, 1 or Q_len, K_len)\n",
    "\n",
    "    Q_m = W_Q(Q).view(-1, Q.size(1), n_head, d_head).transpose(1, 2).contiguous()\n",
    "    K_m = W_K(K).view(-1, K.size(1), n_head, d_head).transpose(1, 2).contiguous()\n",
    "    V_m = W_V(V).view(-1, V.size(1), n_head, d_head).transpose(1, 2).contiguous()\n",
    "    # |Q_m| = (batch_size, n_head, Q_len, d_head)\n",
    "    # |K_m| = (batch_size, n_head, K_len, d_head)\n",
    "    # |V_m| = (batch_size, n_head, K_len, d_head)\n",
    "\n",
    "    attention_mask_m = attention_mask.unsqueeze(1)\n",
    "    # |attention_mask| = (batch_size, 1, 1 or Q_len, K_len)\n",
    "\n",
    "    attn_out_m = scale_dot_product_attention(Q_m, K_m, V_m, attention_mask_m)\n",
    "    # |attn_out_m| = (batch_size, n_head, Q_len, d_head)\n",
    "\n",
    "    attn_out_c = attn_out_m.transpose(1, 2).contiguous().view(-1, Q.size(1), n_head * d_head)\n",
    "    # |attn_out_c| = (batch_size, Q_len, n_head * d_head)\n",
    "\n",
    "    attn_out = W_O(attn_out_c)\n",
    "    # |attn_out_c| = (batch_size, Q_len, hidden_dim)\n",
    "\n",
    "    return attn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd8c113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder self attention\n",
    "Q = enc_hidden\n",
    "K = enc_hidden\n",
    "V = enc_hidden\n",
    "attention_mask = enc_mask\n",
    "\n",
    "multi_head_product_attention(Q, K, V, attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb36a572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder self attention\n",
    "Q = dec_hidden\n",
    "K = dec_hidden\n",
    "V = dec_hidden\n",
    "attention_mask = dec_mask\n",
    "\n",
    "multi_head_product_attention(Q, K, V, attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eb729f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross attention\n",
    "Q = dec_hidden\n",
    "K = enc_hidden\n",
    "V = enc_hidden\n",
    "attention_mask = enc_mask\n",
    "\n",
    "scale_dot_product_attention(Q, K, V, attention_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d253e315",
   "metadata": {
    "id": "d253e315",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## train t5 nmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e40d24",
   "metadata": {
    "id": "d2e40d24"
   },
   "outputs": [],
   "source": [
    "# run src/transformer/train_transformer.sh\n",
    "!sh train_transformer.sh \"cchyun-t5-nmt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d843580",
   "metadata": {
    "id": "1d843580",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## translate t5 nmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1934a312",
   "metadata": {
    "id": "1934a312"
   },
   "outputs": [],
   "source": [
    "# src/transformer/translate_transformer.sh\n",
    "!sh translate_transformer.sh \"../../checkpoints/cchyun-t5-nmt-20240322-114508/checkpoint-56330\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa1a59a",
   "metadata": {
    "id": "6aa1a59a",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## infer t5 nmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106b04cb",
   "metadata": {
    "id": "106b04cb"
   },
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    T5TokenizerFast,\n",
    "    GenerationConfig,\n",
    "    T5ForConditionalGeneration,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590023d8",
   "metadata": {
    "id": "590023d8"
   },
   "outputs": [],
   "source": [
    "device = (\n",
    "    torch.device(\"cpu\")\n",
    ")\n",
    "\n",
    "model_fn = \"../../checkpoints/cchyun-t5-nmt-20240322-114508/checkpoint-56330\"\n",
    "\n",
    "tokenizer = T5TokenizerFast.from_pretrained(model_fn)\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_fn)\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b3e8ff",
   "metadata": {
    "id": "96b3e8ff"
   },
   "outputs": [],
   "source": [
    "generation_config = GenerationConfig(\n",
    "        max_new_tokens=512,\n",
    "        early_stopping=True,\n",
    "        do_sample=False,\n",
    "        num_beams=8,\n",
    "        use_cache=True,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        bos_token_id=tokenizer.bos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        decoder_start_token_id=tokenizer.bos_token_id,\n",
    "        repetition_penalty=1.2,\n",
    "        length_penalty=1.0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da85bc5",
   "metadata": {
    "id": "9da85bc5"
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    print(\"input> \", end=\"\")\n",
    "    line = str(input())\n",
    "    if len(line) == 0:\n",
    "        break\n",
    "\n",
    "    x = tokenizer(\n",
    "        line,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\",\n",
    "    )[\"input_ids\"].to(device)\n",
    "\n",
    "    beam_output = model.generate(\n",
    "        input_ids=x,\n",
    "        generation_config=generation_config,\n",
    "    )\n",
    "    result = tokenizer.decode(beam_output[0], skip_special_tokens=True)\n",
    "\n",
    "    print(f\"- ko: {line}\\n- en: {result}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eccc927",
   "metadata": {
    "id": "8eccc927"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "u1t3ki7NxWt9",
    "8e1b6bc1-9d0b-4840-b82d-788da26fb467",
    "60aa673d",
    "b2f7c766-5bf7-444c-b0e1-b1e1e0ac7445",
    "474a87eb-df2f-43d5-b3a3-b1c0076ca7d9",
    "2PUCDkJ4b9ys",
    "ExuAioNUYIx9",
    "ccd8fac1"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
